{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 深度学习中PyTorch的应用",
   "id": "6425704c24fcf05f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# tensor的基本使用",
   "id": "4d00cc3132c5ad63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:01:08.359268Z",
     "start_time": "2025-11-11T16:01:07.792026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def sigmoid_activation(x):\n",
    "    \"\"\" Sigmoid activation function\n",
    "\n",
    "        Arguments:\n",
    "            x: torch.tensor\n",
    "    \"\"\"\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "# Genrate Some Data\n",
    "torch.manual_seed(1) # 设置随机数种子\n",
    "\n",
    "# 定义一个二维tensor\n",
    "features = torch.randn((1, 5))\n",
    "\n",
    "# 定义weights tensor，shape与features相同\n",
    "weights = torch.randn_like(features)\n",
    "\n",
    "# 定义bias tensor\n",
    "bias = torch.randn((1, 1))"
   ],
   "id": "2105906e67d38ef0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们打印构造的tensor shape",
   "id": "a23401064419006f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:02:01.414104Z",
     "start_time": "2025-11-11T16:02:01.411726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(features.shape)\n",
    "print(weights.shape)\n",
    "print(bias.shape)"
   ],
   "id": "5732d3e9af0ab763",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "打印tensor的维度",
   "id": "efd05b0c8513a0a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:02:53.756341Z",
     "start_time": "2025-11-11T16:02:53.753368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(features.dim())\n",
    "print(weights.dim())\n",
    "print(bias.dim())"
   ],
   "id": "f851a3ef8b97ccb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "pytorch中的tensor可以被加减乘除，操作和Numpy一致。通常使用起来和操作Numpy Array一样。\n",
    "<br>\n",
    "通过以上的tensor构造，我们已经拥有了features, weights, bias，我们可以用他构造一个最简单的神经网络"
   ],
   "id": "130b1ba6b32e1204"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:15:20.399224Z",
     "start_time": "2025-11-11T16:15:20.394012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 本案例中使用的是向量，因此可以使用以下三种表达方式\n",
    "\n",
    "# 向量内积 + 求和\n",
    "y1 = sigmoid_activation(torch.sum(features * weights) + bias)\n",
    "y3= sigmoid_activation((features * weights).sum() + bias)\n",
    "\n",
    "# 矩阵乘\n",
    "y2 = sigmoid_activation(torch.mm(features, weights.T) + bias)\n",
    "\n",
    "print(y1, y2, y3)"
   ],
   "id": "4041f5c6c28232d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1457]]) tensor([[0.1457]]) tensor([[0.1457]])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 练习",
   "id": "8d4e4f94af0b04c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:21:53.967991Z",
     "start_time": "2025-11-11T16:21:53.963090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 3 random normal variables\n",
    "features = torch.randn((1, 3))\n",
    "\n",
    "# Define the size of each layer in our network\n",
    "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
    "n_hidden = 2                    # Number of hidden units\n",
    "n_output = 1                    # Number of output units\n",
    "\n",
    "# Weights for inputs to hidden layer\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "# Weights for hidden layer to output layer\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "# and bias terms for hidden and output layers\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))"
   ],
   "id": "d353bb20a6865fb3",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "构造一个多层神经网络，并且可以得到结果为0.3173",
   "id": "41d8300651d9e859"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:23:16.903522Z",
     "start_time": "2025-11-11T16:23:16.900840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y1 = sigmoid_activation(torch.mm(features, W1) + B1)\n",
    "y2 = sigmoid_activation(torch.mm(y1, W2) + B2)\n",
    "print(y1.shape, y2)"
   ],
   "id": "fd811e904f3a71d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2]) tensor([[0.3171]])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Numpy与Torch的转换",
   "id": "660e9e40c4f8db6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:24:12.834297Z",
     "start_time": "2025-11-11T16:24:12.831895Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "da718b74b3c259e6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "numpy数据转torch",
   "id": "a7ec7f420c809b36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:25:53.647183Z",
     "start_time": "2025-11-11T16:25:53.644336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = np.random.rand(4, 3)\n",
    "b = torch.from_numpy(a)"
   ],
   "id": "ae3f5c665c3c9afe",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "torch数据转换为numpy",
   "id": "4258496cf1ef2965"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:26:29.378768Z",
     "start_time": "2025-11-11T16:26:29.377103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.randn([1, 5])\n",
    "b = a.numpy()"
   ],
   "id": "d05149720ef11c7b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "需要注意的是，虽然进行转换了，内部数据是共享地址，我们可以通过如下小实验看出",
   "id": "9da7d621dab779df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:29:21.708189Z",
     "start_time": "2025-11-11T16:29:21.703669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 定义了元素全1的向量\n",
    "a = torch.ones([1, 5])\n",
    "\n",
    "b = a.numpy()\n",
    "\n",
    "# 使用torch inplace的乘法\n",
    "a.mul_(2)\n",
    "print(a, b)"
   ],
   "id": "fbff44e179ac5029",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2.]]) [[2. 2. 2. 2. 2.]]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "75e1e3b33911bd73"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
